---
title: "Exploring transcriptome-wide changes using PCA"
output:
  html_document:
    toc: yes
    toc_float: yes
    toc_depth: 3
    highlight: pygments
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, rows.print = 10)
```

[back to lesson's homepage](https://tavareshugo.github.io/data-carpentry-rnaseq/)

# Lesson Objectives

* Gain an intuitive understanding of principal component analysis (PCA)
* Apply PCA using R's `prcomp()` function and understand the structure of the resulting object
* Use PCA to derive information about structure in multi-dimensional datasets such as RNAseq


#### Further resources

* Short article about PCA using transcriptome data:
    * Jake Lever, Martin Krzywinski & Naomi Altman (2017) [Principal component analysis](https://www.nature.com/articles/nmeth.4346),
Nature Methods 14, 641â€“642
* StatQuest videos by Josh Starmer (watch all of them!): 
    * [Principal Component Analysis (PCA), Step-by-Step](https://youtu.be/FgakZw6K1QQ)
    * [PCA - Practical Tips](https://youtu.be/oRvgq966yZg)
* Book chapters from Holmes & Huber _Modern Statistics for Modern Biology_:
    * [Multivariate Analysis](https://www.huber.embl.de/msmb/Chap-Multivariate.html)
    * [Multivariate methods for heterogeneous data](https://www.huber.embl.de/msmb/Chap-MultivaHetero.html)
    (gives alternatives methods to PCA)


# Setup

In your project's directory, create a new script called `03_pca_samples.R`, 
and start with the following code:

```{r, message = FALSE}
##### setup ####

# load packages
library(tidyverse)

# read the data
trans_cts <- read_csv("./data/counts_transformed.csv")
sample_info <- read_csv("./data/sample_info.csv")
```


# PCA basics

Having expression data for thousands of genes can be overwhelming to explore! 
This is a good example of a multi-dimensional dataset: we have many 
variables (genes) that we want to use to understand patterns of similarity 
between our samples (yeast cells).

There are several methods to help summarise multi-dimensional data, here 
we will show how to use PCA (principal component analysis). 

PCA is a transformation of high-dimensional data into an orthogonal basis such that 
first principal component (PC, aka "axis") is aligned with the largest source of 
variance, the second PC to the largest remaining source of variance and so on. 
This makes high-dimensional data more amenable to visual exploration, as we can 
examine projections to the first two (or few) PCs.

![](figs/pca.png) 
[Link to the original animation](http://setosa.io/ev/principal-component-analysis/)

There are three basic types of information we obtain from a PCA:

* *PC scores* - these are the coordinates of our samples on the new PC axis
* *Eigenvalues* - these represent the variance explained by each PC. 
We can use these to calculate the proportion of variance in the original data 
that each axis explains.
* *Variable loadings* (eigenvectors) - these reflect the "weight" that each variable has on a particular 
PC. These can be thought of as the correlation between the PC and the original variable.


# Running PCA using `prcomp()`

To compute a PCA in R we can use the `prcomp()` function. This function takes a 
matrix of data, where the _columns_ are the _variables_ that we want to use to 
transform our _samples_, which should be the _rows_ of the matrix. 

In our case, we want to look for similarities across our yeast cells (_samples_ = _rows_) 
based on gene expression (_variables_ = _columns_). For that reason, we need 
to provide a _transposed_ version of our table to the `prcomp()` function:

```{r}
# Create a matrix from our table of counts
pca_matrix <- trans_cts %>% 
  # exclude the gene column
  select(-gene) %>% 
  # coerce to a matrix
  as.matrix()

# Assign row names to the matrix
rownames(pca_matrix) <- trans_cts$gene

# Transpose the matrix so that rows = samples and columns = variables
pca_matrix <- t(pca_matrix)

# Perform the PCA
sample_pca <- prcomp(pca_matrix)
```

----

**Exercise:**

> Examine the output of the `prcomp()` function.

[Link to full exercise](00_exercises.html#31_examine_prcomp()_output)

----

#### A note about matrices

A `matrix` is another type of object in R. 
Matrices are a bit similar to `data.frame`, but they only contain values of a 
single type, in this case numeric values (whereas in a `data.frame` different 
columns can contain different types of data). 

In bioinformatics packages you will often have data stored in these matrix objects. 
It is therefore useful to know how to access values in them and how to convert them 
to a `data.frame`.

You can access values in a matrix using `[rows, columns]` notation:

```{r}
# Look at the first 10 rows and first 5 columns of the matrix
pca_matrix[1:10, 1:5]
```

To convert this matrix into a `tibble` object we can use the function `as_tibble()`:

```{r, results=FALSE}
# Convert matrix to tibble
as_tibble(pca_matrix)
```

But now we've lost our sample names (which were the row names of the matrix)! 
If we look at the function's help (`?as_tibble`), we can see that there's a way 
to solve this problem:

```{r, results=FALSE}
# Convert matrix to tibble - add colnames to a new column called "gene"
as_tibble(pca_matrix, rownames = "sample")
```

Now you know how to convert a `matrix` to a `data.frame`, which can be a very handy 
trick to have!


#### Important note

Often it is a good idea to _standardize_ the variables before doing the PCA. 
This is often done by _centering_ the data on the mean and then _scaling_ it by 
dividing by the standard deviation. This ensures that the PCA is not too influenced 
by genes with higher absolute expression. By default, the `prcomp()` function 
does the centering but not the scaling. See the `?prcomp` help to see how to change 
this default behaviour. In this case, because we are using the 
transformed data, this is not too much of an issue, but try re-running the PCA 
with the _centered_ and _scaled_ data to see how it changes it. 

Note that _scaling_ is particularly recommended if your variables are on different 
scales.

We talk more about standardizing gene expression data in the 
[gene clustering lesson](04b_rnaseq_clustering.html).



### Variance explained by PCs

Thr first important question to ask after we do a PCA is how many PCs we have and 
how much variance they explain.

We need to extract the variance explained by each PC from our `sample_pca` object.
We could do this "manually", using `sample_pca$sdev^2`, but instead we will use a 
function from the [`broom` package](https://cran.r-project.org/web/packages/broom/vignettes/broom.html)
which conveniently formats the data for plotting:

```{r}
library(broom)

# PC variances (eigen values)
tidy(sample_pca, matrix = "eigenvalues")
```

This table can easily be used to produce a _Scree Plot_, which shows the fraction 
of total variance explained by each principal component. We will show both the 
variance explained by individual PCs as well as the cumulative variance, using a 
type of visualisation known as a [pareto chart](https://en.wikipedia.org/wiki/Pareto_chart):

```{r}
tidy(sample_pca, matrix = "eigenvalues") %>% 
  ggplot(aes(x = factor(PC))) +
  geom_col(aes(y = percent)) +
  geom_line(aes(y = cumulative, group = 1)) + 
  geom_point(aes(y = cumulative)) +
  labs(x = "Principal component", y = "Fraction variance explained")
```

You can see how successive PCs explain less and less of the total variance in the 
original data. Also note that `r length(sample_pca$sdev)` components are enough to 
virtually explain _all_ of the variance in our dataset. This makes sense in this 
case since we only have 36 biological samples.


### Visualising samples on PC space

`prcomp()` returns an oject of its own class. To access individual elements from 
this object, we use the `$` notation, similarly to how you can access individual 
columns from a _data.frame_. 

For example, let's create a plot with our samples plotted on the new PC axis. 

```{r}
# The PC scores are stored in the "x" value of the prcomp object, which is a matrix
pc_scores <- sample_pca$x 

# Make PCA plot
pc_scores %>% 
  # convert it to a tibble retaining the sample names as a new column
  as_tibble(rownames = "sample") %>% 
  # create the plot
  ggplot(aes(x = PC1, y = PC2)) +
  geom_point()
```

This is a very simple plot, but already we can see there is some structure in our 
data, suggesting clusters of samples that are more similar to each other.


----

**Exercise:**

> Modify the code above to recreate the plot below. Save the plot in an object called `pca_plot`

[Link to full exercise](00_exercises.html#32_annotating_pc_plot)

```{r, echo=FALSE}
# The PC scores are stored in the "x" value of the prcomp object, which is a matrix
pca_plot <- sample_pca$x %>% 
  # convert it to a tibble retaining the sample names as a new column
  as_tibble(rownames = "sample") %>% 
  # join with "sample_info" table 
  full_join(sample_info, by = "sample") %>% 
  # create the plot
  ggplot(aes(x = PC1, y = PC2, colour = factor(minute), shape = strain)) +
  geom_point()
pca_plot
```

----

From this plot, we can see that:

* samples seem to cluster by time-point (is it related to time of exposure to 
stress? Or perhaps cell cycle phase, which was not controlled for?)
* T120 and T180 seem to be undistinguishable using PC1 and PC2 (but they might 
be distinguishable if we explore other PC axis!). 
* the genotype does not drive major changes in the transcriptome (but, again, 
it doesn't mean that no genes differ between the genotypes, just that they don't 
explain most of the variance captured by PC1 and PC2)


### Exploring correlation between genes and PCs

Finally, to be able to interpret our PC-axis we need to ask the question of 
which genes have the most influence on each PC axis. This information is contained 
in the variable loadings of the PCA, within the `rotation` value of the `prcomp` object.

We have seen how to extract the variable loadings "manually":

```{r}
# extract values
sample_pca$rotation %>% 
  # convert to a tibble
  as_tibble(rownames = "gene")
```

But, again, we can use the `broom` package, which instead returns a table in a "long" 
format:

```{r}
# variable loadings (eigen vectors) for genes that were used as variables in PCA
tidy(sample_pca, matrix = "loadings")
```

From these data, we can extract the genes with the highest eigenvalues along PC1 
and PC2 using some `dplyr` tricks. 

```{r}
top_genes <- sample_pca %>% 
  # extract variable (gene) loadings
  tidy(matrix = "loadings") %>%  
  # retain only PC1 and PC2
  filter(PC %in% c(1, 2)) %>%
  # for each PC
  group_by(PC) %>%
  # sort descending value
  arrange(desc(abs(value))) %>%
  # take top 5 rows of each PC group
  slice(1:5) %>%
  # extract the column (gene name) from the table
  pull(column) %>%
  # retain unique gene names only
  unique()

top_genes
```

Now, let's use this list of gene names to subset the eigenvalues table:

```{r}
gene_loadings <- sample_pca$rotation %>% 
  as_tibble(rownames = "gene") %>% 
  filter(gene %in% top_genes)
```

We can use this to plot the loadings of each gene along PC1 and PC2:

```{r}
loadings_plot <- ggplot(gene_loadings) +
  geom_segment(aes(x = 0, y = 0, xend = PC1, yend = PC2), 
               arrow = arrow(length = unit(0.1, "in")),
               colour = "brown") +
  geom_text(data = gene_loadings, 
            aes(x = PC1, y = PC2, label = gene),
            nudge_y = 0.005, size = 3) +
  scale_x_continuous(expand = c(0.02, 0.02))

loadings_plot
```

Using the [`patchwork`](https://patchwork.data-imaginist.com/) 
package, we put these two plots side by side to get a 
more complete and interpretable view of our PCA analysis:

```{r, fig.width=8, fig.height=3}
library(patchwork)

# Adjust some aspects of each plot
pca_plot <- pca_plot + 
  coord_fixed(ratio = 0.4) + 
  labs(title = "PC scores") +
  theme(legend.position = "none")

loadings_plot <- loadings_plot + 
  coord_fixed(ratio = 0.4) + 
  labs(title = "PC loadings")

# Put them together
(pca_plot | loadings_plot) + plot_annotation(tag_levels = "A")
```

Notice how we've forced our PC1 axis to be around twice as long as the PC2 
axis (with `coord_fixed()`. 
This is because the variance explained by PC1 is about twice 
as large as the variance explained by PC2.


### Quick visualisation shortcut

This was all very useful to understand how PCA works and how to fully explore 
its results. However, it can sometimes be convenient to produce these graphs 
quickly. 

We can use the `autoplot()` function from the `ggfortify` package to do this:

```{r}
library(ggfortify)
autoplot(sample_pca)
```

There's also information about how much variation each principal component axis 
explains. 

We can annotate this plot further by providing the `autoplot()` function with 
our sample information data (see `?autoplot.prcomp` for more information):

```{r}
autoplot(sample_pca, data = sample_info, colour = "minute", shape = "strain")
```

Finally, you _could_ easily add information about loadings to the plot by adding the 
options `loadings = TRUE, loadings.label = TRUE`. But don't do it, because we 
have thousands of genes, so the plot would be un-interpretable (and probably 
crash your computer)!

```{r, eval=FALSE}
# Example using iris dataset
autoplot(prcomp(iris[, -5]), data = iris, colour = "Species",
         loadings = TRUE, loadings.label = TRUE)
```


# Final thoughts

PCA is an essential and very powerful technique for exploratory data analysis of 
multivariate data. As you see from this example, we can quickly see how our 
data is _structured_, based on transcriptome-wide signatures. 

Note that lack of clustering in a PCA does not mean nothing is happening. Imagine an 
RNAseq experiment where only a dozen genes changed due to your treatment. Because 
there's few genes, transcriptome-wide you might not capture structure in the data. 

In summary, although this analysis gives some indication of how much influence a 
particular gene has along each PC, it is not a replacement for specialised 
[statistical models](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-014-0550-8) 
and [tools](https://master.bioconductor.org/packages/release/workflows/vignettes/rnaseqGene/inst/doc/rnaseqGene.html) 
that assess specific hypothesis for differential expression between conditions.

Finally, it's worth pointing out that PCA is a linear algorithm. 
There are modern methods for non-linear dimensionality reduction, 
which can sometimes perform better than PCA (but perhaps less easily interpretable). 
Two common methods are called _UMAP_ and _t-SNE_. 
These can be found in the [`umap`](https://cran.r-project.org/web/packages/umap/vignettes/umap.html) and 
[`Rtsne`](https://cran.r-project.org/web/packages/Rtsne/) packages, respectively.



----
[back to lesson's homepage](https://tavareshugo.github.io/data-carpentry-rnaseq/)
